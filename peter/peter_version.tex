\documentclass[12pt, a4paper, onecolumn]{article}
\usepackage{fontspec}
\usepackage{titlesec}
\usepackage{tocloft}
\usepackage[english]{babel}
\usepackage{blindtext}
\usepackage{subfig}
\usepackage{pgf}
\setmainfont{Georgia}
\usepackage{parskip}
\usepackage{float}

\newcommand\sectionfont{\normalfont\fontspec{Arial}\fontsize{14pt}{0}\bfseries}
\newcommand\subsectionfont{\normalfont\fontspec{Arial}\fontsize{13pt}{0}\bfseries}
\newcommand\subsubsectionfont{\normalfont\fontspec{Arial}\fontsize{12pt}{0}\bfseries}
\newcommand\tocsectionfont{\normalfont\fontspec{Arial}\fontsize{12pt}{0}\bfseries}
\newcommand\tocsubsectionfont{\normalfont\fontspec{Arial}\fontsize{11pt}{0}\bfseries}
\newcommand\tocsubsubsectionfont{\normalfont\fontspec{Arial}\fontsize{11pt}{0}}
\newcommand\toctitlefont{\normalfont\fontspec{Arial}\fontsize{16pt}{0}\bfseries}

\titleformat{\section}{\sectionfont}{\thesection}{20pt}{}
\titleformat{\subsection}{\subsectionfont}{\thesubsection}{20pt}{}
\titleformat{\subsubsection}{\subsubsectionfont}{\thesubsubsection}{20pt}{}

\renewcommand{\cftsecfont}{\tocsectionfont}
\renewcommand{\cftsubsecfont}{\tocsubsectionfont}
\renewcommand{\cftsubsubsecfont}{\tocsubsubsectionfont}
\renewcommand{\cftsecpagefont}{\tocsectionfont}
\renewcommand{\cftsubsecpagefont}{\tocsubsectionfont}
\renewcommand{\cftsubsubsecpagefont}{\tocsubsubsectionfont}
\renewcommand{\cfttoctitlefont}{\toctitlefont}

\newcommand{\parag}[1]{
	\textbf{#1} \hspace{0pt} \\
}

\addto\captionsenglish{
	\renewcommand{\contentsname}{Table of Contents}
}

\begin{document}

\subsubsection{Comparison with related evaluation methods}
Yildirim et al. evaluated their solution using five people carrying devices with the application installed. Those five people then carried out experiments where they would test the classes \textit{fall, jump, sit, lay down, and climb stairs}. Each class was tested five times by each individual person, resulting in a total of 25 tests for each class. They do non disclose exactly how they performed the tests (for e.g what altitudes were used when falling). Finally, they conclude by stating that their approach, using merely a threshold bases algorithm as a detector, reached a 100\% success rate in discarding the classes \textit{sit, lay down, climb stairs} as non-falls. However, they state that their solution had difficulties in detecting real falls, as well as differentiate between jumps and falls. Their solution falsely missed 9/25 real falls, and further falsely classified 7/25 jumps as falls. 


Abbate et al. used another evaluation method. They initially, evaluated the bare accuracy of their neural network using a mathematical approach and reached a 100\% score. They did, however, use the same data set when training the model as when they evaluated it, which to a great extent improves the derived accuracy of the network. They further evaluated the actual application using three test persons. The individuals would use it in normal day situations for a period of 82 hours and performed activities such as \textit{jumping, running, walking, sitting, lying down, hitting the sensor and driving a car}. They conclude by stating that their solution reported no falls for these activities, which is a good result with regards to discarding ot false alarms. They do not, however, disclose any information about their application's ability to properly detect a real fall.


Our evalutaion method is a combination of these two methods. We evaluated the accuracy of our neural network using a mathematical approach in python, but in contrary to Abbate et al. we split our data set in two parts, resulting in a 90 \% training and 10\%  evaluation set. This gave us a derived accuracy of 87\%. By using different sets of data for training and evaluation, the "derived accuracy" measurement gives us a value that is more close to the actual accuracy of the network. Further, in common with both Yildirim et al. and Abbate et al. we tested our application in real life scenarios , but used two persons instead of five and three respectively. The test cases also differed to some extent, were our test cases were tailored to test the design of \textit{our} state machine as well as \textit{our} neural network. The major difference in evaluation is that, in contrary to Abbate et al., we also included tests detecting the application ability to detect real falls. 

\end{document}